{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXLA5InzXydn"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "RuRlpLL-X0R_"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvNr2svBM-p3"
   },
   "outputs": [],
   "source": [
    "!pip install -q tf-models-official==2.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U-7qPCjWUAyy"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lXsXev5MNr20"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "from official.modeling import tf_utils\n",
    "from official import nlp\n",
    "from official.nlp import bert\n",
    "\n",
    "# Load the required submodules\n",
    "import official.nlp.optimization\n",
    "import official.nlp.bert.bert_models\n",
    "import official.nlp.bert.configs\n",
    "import official.nlp.bert.run_classifier\n",
    "import official.nlp.bert.tokenization\n",
    "import official.nlp.data.classifier_data_lib\n",
    "import official.nlp.modeling.losses\n",
    "import official.nlp.modeling.models\n",
    "import official.nlp.modeling.networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzRHOLciR8eq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert_config.json',\n",
       " 'bert_model.ckpt.data-00000-of-00001',\n",
       " 'bert_model.ckpt.index',\n",
       " 'vocab.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_folder_bert = \"gs://cloud-tpu-checkpoints/bert/keras_bert/uncased_L-12_H-768_A-12\"\n",
    "tf.io.gfile.listdir(gs_folder_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9uFskufsR2LT"
   },
   "source": [
    "You can get a pre-trained BERT encoder from [TensorFlow Hub](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0dAkUttJAzj"
   },
   "outputs": [],
   "source": [
    "hub_url_bert = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujapVfZ_AKW7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_probs_dropout_prob': 0.1,\n",
       " 'hidden_act': 'gelu',\n",
       " 'hidden_dropout_prob': 0.1,\n",
       " 'hidden_size': 768,\n",
       " 'initializer_range': 0.02,\n",
       " 'intermediate_size': 3072,\n",
       " 'max_position_embeddings': 512,\n",
       " 'num_attention_heads': 12,\n",
       " 'num_hidden_layers': 12,\n",
       " 'type_vocab_size': 2,\n",
       " 'vocab_size': 30522}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "bert_config_file = os.path.join(gs_folder_bert, \"bert_config.json\")\n",
    "config_dict = json.loads(tf.io.gfile.GFile(bert_config_file).read())\n",
    "\n",
    "bert_config = bert.configs.BertConfig.from_dict(config_dict)\n",
    "\n",
    "config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "96ldxDSwkVkj"
   },
   "source": [
    "The `config` defines the core BERT Model, which is a Keras model to predict the outputs of `num_classes` from the inputs with maximum sequence length `max_seq_length`.\n",
    "\n",
    "This function returns both the encoder and the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cH682__U0FBv"
   },
   "outputs": [],
   "source": [
    "max_seq_length = 128\n",
    "initializer = tf.keras.initializers.TruncatedNormal(\n",
    "        stddev=bert_config.initializer_range)\n",
    "bert_encoder = bert.bert_models.get_transformer_encoder(\n",
    "    bert_config, max_seq_length)\n",
    "\n",
    "input_word_ids = tf.keras.layers.Input(\n",
    "  shape=(max_seq_length,), dtype=tf.int32, name='input_word_ids')\n",
    "input_mask = tf.keras.layers.Input(\n",
    "  shape=(max_seq_length,), dtype=tf.int32, name='input_mask')\n",
    "input_type_ids = tf.keras.layers.Input(\n",
    "  shape=(max_seq_length,), dtype=tf.int32, name='input_type_ids')\n",
    "bert_model = hub.KerasLayer(hub_url_bert, trainable=True)\n",
    "pooled_output, seq_output = bert_model([input_word_ids, input_mask, input_type_ids])\n",
    "output1 = tf.keras.layers.Dropout(rate=bert_config.hidden_dropout_prob)(\n",
    "  pooled_output)\n",
    "\n",
    "output1 = tf.keras.layers.Dense(\n",
    "  2, kernel_initializer=initializer, name='output1')(\n",
    "      output1)\n",
    "\n",
    "output2 = tf.keras.layers.Dropout(rate=bert_config.hidden_dropout_prob)(\n",
    "  pooled_output)\n",
    "\n",
    "output2 = tf.keras.layers.Dense(\n",
    "  3, kernel_initializer=initializer, name='output2')(\n",
    "      output2)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "      inputs={\n",
    "          'input_word_ids': input_word_ids,\n",
    "          'input_mask': input_mask,\n",
    "          'input_type_ids': input_type_ids\n",
    "      },\n",
    "      outputs=[output1, output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAQblMIjwkvx"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8L__-erBwLIQ"
   },
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(bert_encoder, show_shapes=True, dpi=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8qXKRZuCwW4"
   },
   "outputs": [],
   "source": [
    "# Set up epochs and steps\n",
    "epochs = 3\n",
    "batch_size = 32\n",
    "eval_batch_size = 32\n",
    "\n",
    "# get train_data_size from metadata\n",
    "train_data_size = 1000\n",
    "steps_per_epoch = int(train_data_size / batch_size)\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(epochs * train_data_size * 0.1 / batch_size)\n",
    "\n",
    "# creates an optimizer with learning rate schedule\n",
    "optimizer = nlp.optimization.create_optimizer(\n",
    "    2e-5, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eQNA16bhDpky"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "official.nlp.optimization.AdamWeightDecay"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCvaLLAxPuMc"
   },
   "outputs": [],
   "source": [
    "# def create_classifier_dataset(file_path, seq_length, batch_size, is_training):\n",
    "#   \"\"\"Creates input dataset from (tf)records files for train/eval.\"\"\"\n",
    "#   dataset = tf.data.TFRecordDataset(file_path)\n",
    "#   if is_training:\n",
    "#     dataset = dataset.shuffle(100)\n",
    "#     dataset = dataset.repeat()\n",
    "\n",
    "#   def decode_record(record):\n",
    "#     name_to_features = {\n",
    "#       'is_real_example': tf.io.FixedLenFeature([], tf.int64),\n",
    "#       'input_ids': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "#       'input_mask': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "#       'segment_ids': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "#       'label_ids': tf.io.FixedLenFeature([], tf.int64),\n",
    "#       'example_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "#     }    \n",
    "#     return tf.io.parse_single_example(record, name_to_features)\n",
    "\n",
    "#   def _select_data_from_record(record):\n",
    "#     return ({\n",
    "#         'input_word_ids': record['input_ids'],\n",
    "#         'input_mask': record['input_mask'],\n",
    "#         'input_type_ids': record['segment_ids']\n",
    "#     }, (record['label_ids'], -tf.ones([seq_length], dtype=tf.int64)))\n",
    "\n",
    "#   dataset = dataset.map(decode_record,\n",
    "#                         num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#   dataset = dataset.map(\n",
    "#       _select_data_from_record,\n",
    "#       num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#   # dataset = dataset.batch(batch_size, drop_remainder=is_training)\n",
    "#   dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#   return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_classifier_dataset(file_path, seq_length, batch_size, is_training):\n",
    "#   \"\"\"Creates input dataset from (tf)records files for train/eval.\"\"\"\n",
    "#   dataset = tf.data.TFRecordDataset(file_path)\n",
    "#   if is_training:\n",
    "#     dataset = dataset.shuffle(100)\n",
    "#     dataset = dataset.repeat()\n",
    "\n",
    "#   def decode_record(record):\n",
    "#     name_to_features = {\n",
    "#       'input_ids': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "#       'input_mask': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "#       'segment_ids': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "#       'label_ids': tf.io.FixedLenFeature([], tf.int64),\n",
    "#     }\n",
    "#     return tf.io.parse_single_example(record, name_to_features)\n",
    "\n",
    "#   def _select_data_from_record(record):\n",
    "#     x = {\n",
    "#         'input_word_ids': record['input_ids'],\n",
    "#         'input_mask': record['input_mask'],\n",
    "#         'input_type_ids': record['segment_ids']\n",
    "#     }\n",
    "#     y = record['label_ids']\n",
    "#     return (x, y)\n",
    "\n",
    "#   dataset = dataset.map(decode_record,\n",
    "#                         num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#   dataset = dataset.map(\n",
    "#       _select_data_from_record,\n",
    "#       num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#   #dataset = dataset.batch(batch_size, drop_remainder=is_training)\n",
    "#   dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#   return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tagging_dataset(file_path, seq_length, batch_size, is_training):\n",
    "  \"\"\"Creates input dataset from (tf)records files for train/eval.\"\"\"\n",
    "  dataset = tf.data.TFRecordDataset(file_path)\n",
    "  if is_training:\n",
    "    dataset = dataset.shuffle(100)\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "  def decode_record(record):\n",
    "    name_to_features = {\n",
    "      'input_ids': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "      'input_mask': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "      'segment_ids': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "      'label_ids': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "      'sub_sentence_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "      'sentence_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }    \n",
    "    return tf.io.parse_single_example(record, name_to_features)\n",
    "\n",
    "  def _select_data_from_record(record):\n",
    "    return ({\n",
    "        'input_word_ids': record['input_ids'],\n",
    "        'input_mask': record['input_mask'],\n",
    "        'input_type_ids': record['segment_ids']\n",
    "    }, (-tf.ones([], dtype=tf.int64), record['label_ids']))\n",
    "\n",
    "  dataset = dataset.map(decode_record,\n",
    "                        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  dataset = dataset.map(\n",
    "      _select_data_from_record,\n",
    "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  # dataset = dataset.batch(batch_size, drop_remainder=is_training)\n",
    "  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Mapping, Optional\n",
    "\n",
    "import dataclasses\n",
    "import tensorflow as tf\n",
    "\n",
    "from official.core import input_reader\n",
    "from official.modeling.hyperparams import config_definitions as cfg\n",
    "from official.nlp.data import data_loader\n",
    "from official.nlp.data import data_loader_factory\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TaggingDataConfig(cfg.DataConfig):\n",
    "  \"\"\"Data config for tagging (tasks/tagging).\"\"\"\n",
    "  is_training: bool = True\n",
    "  seq_length: int = 128\n",
    "  include_sentence_id: bool = False\n",
    "\n",
    "\n",
    "@data_loader_factory.register_data_loader_cls(TaggingDataConfig)\n",
    "class TaggingDataLoader(data_loader.DataLoader):\n",
    "  \"\"\"A class to load dataset for tagging (e.g., NER and POS) task.\"\"\"\n",
    "\n",
    "  def __init__(self, params: TaggingDataConfig):\n",
    "    self._params = params\n",
    "    self._seq_length = params.seq_length\n",
    "    self._include_sentence_id = params.include_sentence_id\n",
    "\n",
    "  def _decode(self, record: tf.Tensor):\n",
    "    \"\"\"Decodes a serialized tf.Example.\"\"\"\n",
    "    name_to_features = {\n",
    "        'input_ids': tf.io.FixedLenFeature([self._seq_length], tf.int64),\n",
    "        'input_mask': tf.io.FixedLenFeature([self._seq_length], tf.int64),\n",
    "        'segment_ids': tf.io.FixedLenFeature([self._seq_length], tf.int64),\n",
    "        'label_ids': tf.io.FixedLenFeature([self._seq_length], tf.int64),\n",
    "    }\n",
    "    if self._include_sentence_id:\n",
    "      name_to_features['sentence_id'] = tf.io.FixedLenFeature([], tf.int64)\n",
    "      name_to_features['sub_sentence_id'] = tf.io.FixedLenFeature([], tf.int64)\n",
    "\n",
    "    example = tf.io.parse_single_example(record, name_to_features)\n",
    "\n",
    "    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "    # So cast all int64 to int32.\n",
    "    for name in example:\n",
    "      t = example[name]\n",
    "      if t.dtype == tf.int64:\n",
    "        t = tf.cast(t, tf.int32)\n",
    "      example[name] = t\n",
    "\n",
    "    return example\n",
    "\n",
    "  def _parse(self, record: Mapping[str, tf.Tensor]):\n",
    "    \"\"\"Parses raw tensors into a dict of tensors to be consumed by the model.\"\"\"\n",
    "    x = {\n",
    "        'input_word_ids': record['input_ids'],\n",
    "        'input_mask': record['input_mask'],\n",
    "        'input_type_ids': record['segment_ids']\n",
    "    }\n",
    "    if self._include_sentence_id:\n",
    "      x['sentence_id'] = record['sentence_id']\n",
    "      x['sub_sentence_id'] = record['sub_sentence_id']\n",
    "\n",
    "    y = record['label_ids']\n",
    "    return (x, y)\n",
    "\n",
    "  def load(self, input_context: Optional[tf.distribute.InputContext] = None):\n",
    "    \"\"\"Returns a tf.dataset.Dataset.\"\"\"\n",
    "    reader = input_reader.InputReader(\n",
    "        params=self._params, decoder_fn=self._decode, parser_fn=self._parse)\n",
    "    return reader.read(input_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_file_dataset(input_file, name_to_features, num_samples=None):\n",
    "  \"\"\"Creates a single-file dataset to be passed for BERT custom training.\"\"\"\n",
    "  # For training, we want a lot of parallel reading and shuffling.\n",
    "  # For eval, we want no shuffling and parallel reading doesn't matter.\n",
    "  d = tf.data.TFRecordDataset(input_file)\n",
    "  if num_samples:\n",
    "    d = d.take(num_samples)\n",
    "  d = d.map(\n",
    "      lambda record: decode_record(record, name_to_features),\n",
    "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "  # When `input_file` is a path to a single file or a list\n",
    "  # containing a single path, disable auto sharding so that\n",
    "  # same input file is sent to all workers.\n",
    "  if isinstance(input_file, str) or len(input_file) == 1:\n",
    "    options = tf.data.Options()\n",
    "    options.experimental_distribute.auto_shard_policy = (\n",
    "        tf.data.experimental.AutoShardPolicy.OFF)\n",
    "    d = d.with_options(options)\n",
    "  return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_record(record, name_to_features):\n",
    "  \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "  example = tf.io.parse_single_example(record, name_to_features)\n",
    "\n",
    "  # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "  # So cast all int64 to int32.\n",
    "  for name in list(example.keys()):\n",
    "    t = example[name]\n",
    "    if t.dtype == tf.int64:\n",
    "      t = tf.cast(t, tf.int32)\n",
    "    example[name] = t\n",
    "\n",
    "  return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier_dataset(file_path,\n",
    "                              seq_length,\n",
    "                              batch_size,\n",
    "                              task_id,\n",
    "                              is_training=True,\n",
    "                              input_pipeline_context=None,\n",
    "                              label_type=tf.int64,\n",
    "                              include_sample_weights=False,\n",
    "                              num_samples=None):\n",
    "  \"\"\"Creates input dataset from (tf)records files for train/eval.\"\"\"\n",
    "  name_to_features = {\n",
    "      'input_ids': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "      'input_mask': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "      'segment_ids': tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "      'label_ids': tf.io.FixedLenFeature([], label_type),\n",
    "  }\n",
    "  if include_sample_weights:\n",
    "    name_to_features['weight'] = tf.io.FixedLenFeature([], tf.float32)\n",
    "  dataset = single_file_dataset(file_path, name_to_features,\n",
    "                                num_samples=num_samples)\n",
    "\n",
    "  # The dataset is always sharded by number of hosts.\n",
    "  # num_input_pipelines is the number of hosts rather than number of cores.\n",
    "  if input_pipeline_context and input_pipeline_context.num_input_pipelines > 1:\n",
    "    dataset = dataset.shard(input_pipeline_context.num_input_pipelines,\n",
    "                            input_pipeline_context.input_pipeline_id)\n",
    "\n",
    "  def _select_data_from_record(record):\n",
    "    x = {\n",
    "        'input_word_ids': record['input_ids'],\n",
    "        'input_mask': record['input_mask'],\n",
    "        'input_type_ids': record['segment_ids']\n",
    "    }\n",
    "    #pdb.set_trace()\n",
    "    y = record['label_ids']\n",
    "    if include_sample_weights:\n",
    "      w = record['weight']\n",
    "      return (x, y, w)\n",
    "    default = tf.constant(-1, dtype=tf.int32)\n",
    "    if task_id ==0:\n",
    "      return (x, [y, default])\n",
    "    if task_id == 1:\n",
    "      return (x, [default,y])\n",
    "\n",
    "  if is_training:\n",
    "    dataset = dataset.shuffle(100)\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "  dataset = dataset.map(\n",
    "      _select_data_from_record,\n",
    "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  #dataset = dataset.batch(batch_size, drop_remainder=is_training)\n",
    "  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sampling (using proportional sampling technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-96169b7cdfc6>:6: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-96169b7cdfc6>:6: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49401\n",
      "392702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11174092914999446, 0.8882590708500055]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_records_filenames = [\"gs://nts2020/xtereme/pawsx/train.en.tfrecords\", \"gs://nts2020/xtereme/xnli/train.en.tfrecords\"]\n",
    "\n",
    "sampling_factor = []\n",
    "for fn in tf_records_filenames:\n",
    "    c = 0\n",
    "    for record in tf.compat.v1.python_io.tf_record_iterator(fn):\n",
    "        c += 1\n",
    "    sampling_factor.append(c)\n",
    "    print(c)\n",
    "c = sum(sampling_factor)\n",
    "for i in range(0, len(sampling_factor)):\n",
    "    sampling_factor[i] = sampling_factor[i]/c\n",
    "sampling_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rutkBadrhzdR"
   },
   "outputs": [],
   "source": [
    "# Set up batch sizes\n",
    "batch_size = 64\n",
    "eval_batch_size = 64\n",
    "\n",
    "# Return Tensorflow dataset\n",
    "paws_training_dataset = create_classifier_dataset(\n",
    "    \"gs://nts2020/xtereme/pawsx/train.en.tfrecords\",\n",
    "    128,\n",
    "    batch_size,\n",
    "    task_id = 0,\n",
    "    is_training=True)\n",
    "\n",
    "xnli_training_dataset = create_classifier_dataset(\n",
    "    \"gs://nts2020/xtereme/xnli/train.en.tfrecords\",\n",
    "    128,\n",
    "    batch_size,\n",
    "    task_id = 1,\n",
    "    is_training=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_word_ids': TensorSpec(shape=(128,), dtype=tf.int32, name=None),\n",
       "  'input_mask': TensorSpec(shape=(128,), dtype=tf.int32, name=None),\n",
       "  'input_type_ids': TensorSpec(shape=(128,), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(2,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paws_training_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_word_ids': TensorSpec(shape=(128,), dtype=tf.int32, name=None),\n",
       "  'input_mask': TensorSpec(shape=(128,), dtype=tf.int32, name=None),\n",
       "  'input_type_ids': TensorSpec(shape=(128,), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(2,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xnli_training_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59TVgt4Z7fuU"
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.data.experimental.sample_from_datasets(\n",
    "    [paws_training_dataset, xnli_training_dataset], weights=tf.constant([sampling_factor[0], sampling_factor[1]])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "paws_eval_dataset = create_classifier_dataset(\n",
    "    \"gs://nts2020/xtereme/pawsx/eval.en.tfrecords\",\n",
    "    128,\n",
    "    batch_size,\n",
    "    task_id = 0,\n",
    "    is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnli_eval_dataset = create_classifier_dataset(\n",
    "    \"gs://nts2020/xtereme/xnli/eval.en.tfrecords\",\n",
    "    128,\n",
    "    batch_size,\n",
    "    task_id =1,\n",
    "    is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset = tf.data.experimental.sample_from_datasets(\n",
    "    [paws_eval_dataset, xnli_eval_dataset], weights=tf.constant([sampling_factor[0], sampling_factor[1]])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_word_ids': TensorSpec(shape=(128,), dtype=tf.int32, name=None),\n",
       "  'input_mask': TensorSpec(shape=(128,), dtype=tf.int32, name=None),\n",
       "  'input_type_ids': TensorSpec(shape=(128,), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(2,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_word_ids': TensorSpec(shape=(128,), dtype=tf.int32, name=None),\n",
       "  'input_mask': TensorSpec(shape=(128,), dtype=tf.int32, name=None),\n",
       "  'input_type_ids': TensorSpec(shape=(128,), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(2,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paws_eval_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_word_ids': TensorSpec(shape=(128,), dtype=tf.int32, name=None),\n",
       "  'input_mask': TensorSpec(shape=(128,), dtype=tf.int32, name=None),\n",
       "  'input_type_ids': TensorSpec(shape=(128,), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(2,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xnli_eval_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_word_ids': TensorSpec(shape=(128,), dtype=tf.int32, name=None),\n",
       "  'input_mask': TensorSpec(shape=(128,), dtype=tf.int32, name=None),\n",
       "  'input_type_ids': TensorSpec(shape=(128,), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(2,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_dataset = training_dataset.batch(batch_size)\n",
    "evaluation_dataset = evaluation_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _loss_with_filter(y_true, y_pred):\n",
    "#   #pdb.set_trace()\n",
    "#   num_labels = y_pred.get_shape().as_list()[-1]\n",
    "#   log_probs = tf.nn.log_softmax(y_pred, axis=-1)\n",
    "#   log_probs = tf.reshape(log_probs, [-1, num_labels])\n",
    "#   labels = tf.reshape(y_true, [-1])\n",
    "    \n",
    "#   if y_pred.get_shape().as_list()[-1] == 2:\n",
    "#       one_hot_labels = tf.identity(labels)\n",
    "#       one_hot_labels = tf.cast(one_hot_labels, tf.float32)  \n",
    "#   else:\n",
    "#       one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "#   per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "#   loss = tf.reduce_mean(per_example_loss)\n",
    "#   pdb.set_trace()\n",
    "#   return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _loss_mod(y_true, y_pred):\n",
    "  #pdb.set_trace()\n",
    "  num_labels = y_pred.get_shape().as_list()[-1]\n",
    "  task_id = tf.math.argmax(input = y_true[-1])\n",
    "  #labels = tf.reshape(y_true, [-1])\n",
    "  one_hot_labels = tf.one_hot(y_true[-1][task_id], depth=num_labels, dtype=tf.float32) \n",
    "  #tf.print(one_hot_labels)\n",
    "  #one_hot_labels = tf.compat.v1.Print(one_hot_labels, [y_true, y_pred], 'output = ', summarize=500)\n",
    "  log_probs = tf.nn.log_softmax(y_pred, axis=-1)\n",
    "  per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "  loss = tf.reduce_mean(per_example_loss) \n",
    "  #pdb.set_trace()\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 1670s 2s/step - loss: 1.6130 - output1_loss: 0.5317 - output2_loss: 1.0813 - output1_accuracy: 0.4548 - output2_accuracy: 0.2606 - val_loss: 1.5781 - val_output1_loss: 0.4172 - val_output2_loss: 1.1610 - val_output1_accuracy: 0.4062 - val_output2_accuracy: 0.1281\n",
      "Epoch 2/3\n",
      " 483/1000 [=============>................] - ETA: 14:21 - loss: 1.6035 - output1_loss: 0.4996 - output2_loss: 1.1040 - output1_accuracy: 0.4643 - output2_accuracy: 0.2663"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
    "loss1 = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "loss2 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = [_loss_mod, _loss_mod], metrics = metrics)\n",
    "model.fit(training_dataset, batch_size = batch_size, epochs= 3, steps_per_epoch = 1000, validation_data=evaluation_dataset, validation_steps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy1', dtype=tf.float32),\n",
    "#            tf.keras.metrics.SparseCategoricalAccuracy('accuracy2', dtype=tf.float32)]\n",
    "\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy('accuracy', dtype=tf.float32), tf.keras.metrics.]\n",
    "loss1 = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "loss2 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# TODO(henrytsai):\n",
    "# def _loss_with_filter(y_true, y_pred):\n",
    "# filters out `-1` labels.\n",
    "\n",
    "# training_dataset = training_dataset.batch(32)\n",
    "# model.compile(\n",
    "#     optimizer=optimizer,\n",
    "#     # Add more losses here.\n",
    "#     loss=[loss1, loss2])\n",
    "\n",
    "training_dataset = training_dataset.batch(32)\n",
    "# paws_training_dataset = paws_training_dataset.batch(32)\n",
    "# xnli_training_dataset = xnli_training_dataset.batch(32)\n",
    "model.compile(optimizer = optimizer, loss = [_loss_with_filter, _loss_with_filter], metrics = metrics)\n",
    "model.fit(training_dataset, batch_size = 32, epochs= epochs, steps_per_epoch = 1000)\n",
    "# model.fit(\n",
    "#       training_dataset,\n",
    "#       batch_size=32,\n",
    "#       epochs=epochs,\n",
    "#       steps_per_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paws_training_dataset = paws_training_dataset.batch(2, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paws_training_dataset = create_classifier_dataset(\n",
    "    \"gs://nts2020/xtereme/pawsx/train.en.tfrecords\",\n",
    "    128,\n",
    "    batch_size,\n",
    "    is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udpos_training_dataset = udpos_training_dataset.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in paws_training_dataset.as_numpy_iterator():\n",
    "  print(element)\n",
    "  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in xnli_training_dataset.as_numpy_iterator():\n",
    "  print(element)\n",
    "  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in training_dataset.as_numpy_iterator():\n",
    "  print(element)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in evaluation_dataset.as_numpy_iterator():\n",
    "  print(element[0]['input_word_ids'].shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fine_tuning_bert.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "common-cu101.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu101:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
